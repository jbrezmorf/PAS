
% $Header: /cvsroot/latex-beamer/latex-beamer/solutions/generic-talks/generic-ornate-15min-45min.en.tex,v 1.5 2007/01/28 20:48:23 tantau Exp $

\documentclass[smaller]{beamer}
\mode<presentation>
{
  \usetheme{Singapore}
  \usefonttheme[onlymath]{serif}
  % or ...
 %  \setbeamercovered{transparent}
  % or whatever (possibly just delete it)
}


\usepackage[czech]{babel}
% or whatever
\usepackage[utf8]{inputenc}
% or whatever
%\usepackage{times}
%\usepackage[T1]{fontenc}
% Or whatever. Note that the encoding and the font should match. If T1
% does not look nice, try deleting the line with the fontenc.


\title{PAS06 -- Parameter estimates}

\author{Jan B\v rezina}
\institute % (optional, but mostly needed)
{
  %\inst{2}%
  Technical University of Liberec
}


% If you wish to uncover everything in a step-wise fashion, uncomment
% the following command: 

%\beamerdefaultoverlayspecification{<+->}

% ***************************************** SYMBOLS
\def\div{{\rm div}}
\def\Lapl{\Delta}
\def\grad{\nabla}
\def\supp{{\rm supp}}
\def\dist{{\rm dist}}
%\def\chset{\mathbbm{1}}
\def\chset{1}

\def\Tr{{\rm Tr}}
\def\sgn{{\rm sgn}}
\def\to{\rightarrow}
\def\weakto{\rightharpoonup}
\def\imbed{\hookrightarrow}
\def\cimbed{\subset\subset}
\def\range{{\mathcal R}}
\def\leprox{\lesssim}
\def\argdot{{\hspace{0.18em}\cdot\hspace{0.18em}}}
\def\Distr{{\mathcal D}}
\def\calK{{\mathcal K}}
\def\FromTo{|\rightarrow}
\def\convol{\star}
\def\impl{\Rightarrow}
\DeclareMathOperator*{\esslim}{esslim}
\DeclareMathOperator*{\esssup}{ess\,sup}
\DeclareMathOperator{\ess}{ess}
\DeclareMathOperator{\osc}{osc}
\DeclareMathOperator{\curl}{curl}

%\def\Ess{{\rm ess}}
%\def\Exp{{\rm exp}}
%\def\Implies{\Longrightarrow}
%\def\Equiv{\Longleftrightarrow}
% ****************************************** GENERAL MATH NOTATION
\def\Real{{\rm\bf R}}
\def\Rd{{{\rm\bf R}^{\rm 3}}}
\def\RN{{{\rm\bf R}^N}}
\def\D{{\mathbb D}}
\def\Nnum{{\mathbb N}}
\def\Measures{{\mathcal M}}
\def\d{\,{\rm d}}               % differential
\def\sdodt{\genfrac{}{}{}{1}{\rm d}{{\rm d}t}}
\def\dodt{\genfrac{}{}{}{}{\rm d}{{\rm d}t}}

\def\vc#1{\mathbf{\boldsymbol{#1}}}     % vector
\def\tn#1{{\mathbb{#1}}}    % tensor
\def\abs#1{\lvert#1\rvert}
\def\Abs#1{\bigl\lvert#1\bigr\rvert}
\def\bigabs#1{\bigl\lvert#1\bigr\rvert}
\def\Bigabs#1{\Big\lvert#1\Big\rvert}
\def\ABS#1{\left\lvert#1\right\rvert}
\def\norm#1{\bigl\Vert#1\bigr\Vert} %norm
\def\close#1{\overline{#1}}
\def\inter#1{#1^\circ}
\def\ol#1{\overline{#1}}
\def\ul#1{\underline{#1}}
\def\eqdef{\mathrel{\mathop:}=}     % defining equivalence
\def\where{\,|\,}                    % "where" separator in set's defs
\def\timeD#1{\dot{\overline{{#1}}}}

% ******************************************* USEFULL MACROS
\def\RomanEnum{\renewcommand{\labelenumi}{\rm (\roman{enumi})}}   % enumerate by roman numbers
\def\rf#1{(\ref{#1})}                                             % ref. shortcut
\def\prtl{\partial}                                        % partial deriv.
\def\Names#1{{\scshape #1}}
\def\rem#1{{\parskip=0cm\par!! {\sl\small #1} !!}}

\def\Xint#1{\mathchoice
{\XXint\displaystyle\textstyle{#1}}%
{\XXint\textstyle\scriptstyle{#1}}%
{\XXint\scriptstyle\scriptscriptstyle{#1}}%
{\XXint\scriptscriptstyle\scriptscriptstyle{#1}}%
\!\int}
\def\XXint#1#2#3{{\setbox0=\hbox{$#1{#2#3}{\int}$}
\vcenter{\hbox{$#2#3$}}\kern-.5\wd0}}
\def\ddashint{\Xint=}
\def\dashint{\Xint-}

% ******************************************* DOCUMENT NOTATIONS
% document specific
\def\rh{\varrho}
\def\vl{{\vc{u}}}
\def\th{\vartheta}
\def\vx{\vc{x}}
\def\vX{\vc{X}}
\def\vr{\vc{r}}
\def\veta{\vc{\eta}}
\def\dx{\,\d\vx}
\def\dt{\,\d t}
\def\bulk{\zeta}
\def\cS{\close{S}}
\def\eps{\varepsilon}
\def\phi{\varphi}
\def\Bog{{\mathcal B}}
\def\Riesz{{\mathcal R}}
\def\distr{\mathcal D}
\def\Item{$\bullet$}
\def\MEtst{\mathcal T}
%***************************************************************************
% highlight color
\setbeamercolor{my blue}{fg=blue}
\def\blue#1{{\usebeamercolor[fg]{my blue} #1}}

\setbeamercolor{my green}{fg=green}
\def\green#1{{\usebeamercolor[fg]{my green} #1}}

% color for term definition
\setbeamercolor{my orange}{fg=orange}
\def\df#1{{\usebeamercolor[fg]{my orange} #1}}
\def\xskip{{\vspace{2ex}}}

\def\cz#1{{\small (#1)}}

\def\E{\vc{\mathsf{E}}}

\begin{document}

\begin{frame}
  \titlepage
\end{frame}


\begin{frame}{Motivation}
 \begin{itemize}
  \item  We perform a measurement with normal distributed error. but we do not know parameters $\mu$ and $\sigma^2$.
    How can we estimate them from measured data? How precisely?
  \item What max. number of defects can producer guarantee in package of 100 products so that probability to warranty claim is less then 1\%?\\
        That is: binomial distribution, unknown $p$, and we want to estimate $1\%$-quantile.
  \item We compare two drugs against blood coagulation (srážlivost). What is the difference in their efficiency?
 \end{itemize}

\end{frame}


\begin{frame}{Point estimate}
Random vector $\vc X$ of independent random variables with the same distribution, that depends on a parameter vector
$\vc \theta \in \Theta \subset \Real^N$, i.e.
\[
 \vc F_{\vc X}(\vc x, \vc \theta) = \prod_{i=1}^n F(x_i,\vc \theta)
\]

\xskip
\blue{The problem:} For known $F(x,\vc theta)$ and $n$ find a vector function (statistics) $\vc T_n(\vc X)$ that can estimate parameter $\vc \theta$.

Result $\vc T_n$ is a new random variable.

For fixed $\vc \theta$ we denote $\E_\theta \vc T_n$ and $var_\theta \vc T_n$ the expectation and the variance of $\vc T_n$.

\xskip
Further,  we consider only scalar statistics (single parameter estimate) $T_n(\vc X)$.
\end{frame}

\begin{frame}{Examples of point estimates.}
 \begin{itemize}
  \item Estimate of the expectation (for any distribution) is the mean value.
        \[
            \E X_i = \mu \approx T_n(\vc X) = \frac{1}{n} \sum_i X_i
        \]

  \item Estimate of the probability $p$ of a binomial RV, is the sample relative frequency $n_i / n$.

  \item Estimate of variance is  sample variance.
        \[
            DX_i = \sigma^2 \approx T_n(\vc X) = S_n^2 =\frac{1}{n-1} \sum_{i=1}^n (X_i - \overline{X})^2 
        \]
 \end{itemize}

\end{frame}


\begin{frame}{Required properties of point estimates}
 
  \blue{Unbiased \cz{nestrannost, nevychýlenost}:}\\
  The expectation of the estimate, $E_\theta T_n$, is equal to the true parameter $\vc \theta$.
  
  \xskip
  \blue{Consistency \cz{konzistence}:}\\
  $T_n(\vc X)$ converge (strongly) to $\vc \theta$ for $n\to \infty$.

  \xskip
  \blue{Efficiency \cz{efficientní odhad}:}\\
  The estimate has the smallest variance from all possible estimates.

  \xskip
  \blue{Asymptomatic normality:}\\
   For large $n$ the estimate has nearly normal distribution.

\end{frame}


\begin{frame}{Unbiased mean value estimator}
\[	
   \E_\theta T_n = \vc \theta
\]

\xskip
Eg. sample mean is unbiased estimate of mean value,\\
using linearity of expectation:
\[ 
   \E_\mu \overline{X} = \frac{1}{n} \sum_{i=1}^n \E X_i = \mu
\]
\end{frame}

\begin{frame}{Unbiased estimate of variance}
For known mean value $\mu$:
\[
   S_n^2 = \frac{1}{n} \sum_{i=1}^n (X_i - \mu)^2
\]

for unknown mean value (common case):
\[
  S_n^2 = \frac{1}{n-1} \sum_{i=1}^n (X_i - \overline{X})^2 = \frac{1}{n-1} \Big(\sum_i X_i^2\Big) - n\overline{X}^2
\]

\end{frame}

\begin{frame}{Proof:}
 
 \blue{1)} Let $X_i$ be independent RV with mean value $\mu$ and variance $\sigma^2$, than
\[
   var(\overline{X}) = \frac{1}{n^2}\sum_{i=1}^n var(X_i) = \frac{\sigma^2}{n}
\]

  \blue{2)}
\begin{align*}
   \E (n-1)S^2 = \E \sum_i (X_i- \ol{X})^2 =\E \sum_i \big[(X_i-\mu) - (\overline{X} -\mu)\big]^2=\\
   =\E  \sum_i (X_i-\mu)^2 - \E n(\overline{X} -\mu)^2 =
n\sigma^2 - \sigma^2
\end{align*}
\end{frame}

\begin{frame}{Strong consistency}
\[
   \lim_{n\to \infty} T_n(\vc X) = \theta
\]
with probability $1$. I.e. almost sure convergence.
\xskip
Example:
Strong law of big numbers proofs, that sample mean is converge to the true mean value and thus
it is consistent estimate.
\end{frame}

\begin{frame}{Efficiency}
Estimate with the smallest variance:
\[
\E_\theta(T_n(\vc X) - \theta)^2 \le \E_\theta(T_n^{\star}(\vc X) - \theta)^2
\]
for any other estimator $T_n^{\star}$.

\end{frame}

\begin{frame}{Asymptotic normality}
For sample mean, we can use the central limit theorem:
\[
 \sqrt{n}\frac{\ol{X} - EX}{s} 
\]
converge in distribution to $N(0,1)$

For some other estimates (sample variance) we have:
\[
 T_n(X) - \theta
\]
is close to  $N(0,\sigma^2)$ for suitable $\sigma(n)$.
\end{frame}

\begin{frame}{Maximum likelihood method}
\df{likelihood function}\cz{věrohodnostní funkce}:
 \[
    L_{\theta} (\vc x) = f_{\vc x}(\vc x, \theta) = \prod_i f(x_i, \theta)
 \]

Given a sample $\vc x$ of independent values,
\df{maximum-likelihood estimator} is value $\theta_0$ for which $L_{\theta_0} (\vc x)$ is maximal.

Usually we solve equation: 
\[
   \frac{\prtl}{\prtl \theta} log( L_\theta(\vc x)) = \sum_i \frac{\prtl}{\prtl \theta} log( f(x_i, \theta)) =0
\]

\blue{Example} for binomial variable \dots

\end{frame}

\end{document}


