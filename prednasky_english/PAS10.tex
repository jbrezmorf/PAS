
% $Header: /cvsroot/latex-beamer/latex-beamer/solutions/generic-talks/generic-ornate-15min-45min.en.tex,v 1.5 2007/01/28 20:48:23 tantau Exp $

\documentclass[smaller]{beamer}
\mode<presentation>
{
  \usetheme{Singapore}
  \usefonttheme[onlymath]{serif}
  % or ...
 %  \setbeamercovered{transparent}
  % or whatever (possibly just delete it)
}

\usepackage{amssymb}
\usepackage[czech]{babel}
% or whatever
\usepackage[utf8]{inputenc}
% or whatever
%\usepackage{times}
%\usepackage[T1]{fontenc}
% Or whatever. Note that the encoding and the font should match. If T1
% does not look nice, try deleting the line with the fontenc.


\title{PAS10 -- Goodness of fit test}

\author{Jan B\v rezina}
\institute % (optional, but mostly needed)
{
  %\inst{2}%
  Technical University of Liberec
}


% If you wish to uncover everything in a step-wise fashion, uncomment
% the following command: 

%\beamerdefaultoverlayspecification{<+->}

% ***************************************** SYMBOLS
\def\div{{\rm div}}
\def\Lapl{\Delta}
\def\grad{\nabla}
\def\supp{{\rm supp}}
\def\dist{{\rm dist}}
%\def\chset{\mathbbm{1}}
\def\chset{1}

\def\Tr{{\rm Tr}}
\def\sgn{{\rm sgn}}
\def\to{\rightarrow}
\def\weakto{\rightharpoonup}
\def\imbed{\hookrightarrow}
\def\cimbed{\subset\subset}
\def\range{{\mathcal R}}
\def\leprox{\lesssim}
\def\argdot{{\hspace{0.18em}\cdot\hspace{0.18em}}}
\def\Distr{{\mathcal D}}
\def\calK{{\mathcal K}}
\def\FromTo{|\rightarrow}
\def\convol{\star}
\def\impl{\Rightarrow}
\DeclareMathOperator*{\esslim}{esslim}
\DeclareMathOperator*{\esssup}{ess\,sup}
\DeclareMathOperator{\ess}{ess}
\DeclareMathOperator{\osc}{osc}
\DeclareMathOperator{\curl}{curl}

%\def\Ess{{\rm ess}}
%\def\Exp{{\rm exp}}
%\def\Implies{\Longrightarrow}
%\def\Equiv{\Longleftrightarrow}
% ****************************************** GENERAL MATH NOTATION
\def\Real{{\rm\bf R}}
\def\Rd{{{\rm\bf R}^{\rm 3}}}
\def\RN{{{\rm\bf R}^N}}
\def\D{{\mathbb D}}
\def\Nnum{{\mathbb N}}
\def\Measures{{\mathcal M}}
\def\d{\,{\rm d}}               % differential
\def\sdodt{\genfrac{}{}{}{1}{\rm d}{{\rm d}t}}
\def\dodt{\genfrac{}{}{}{}{\rm d}{{\rm d}t}}

\def\vc#1{\mathbf{\boldsymbol{#1}}}     % vector
\def\tn#1{{\mathbb{#1}}}    % tensor
\def\abs#1{\lvert#1\rvert}
\def\Abs#1{\bigl\lvert#1\bigr\rvert}
\def\bigabs#1{\bigl\lvert#1\bigr\rvert}
\def\Bigabs#1{\Big\lvert#1\Big\rvert}
\def\ABS#1{\left\lvert#1\right\rvert}
\def\norm#1{\bigl\Vert#1\bigr\Vert} %norm
\def\close#1{\overline{#1}}
\def\inter#1{#1^\circ}
\def\ol#1{\overline{#1}}
\def\ul#1{\underline{#1}}
\def\eqdef{\mathrel{\mathop:}=}     % defining equivalence
\def\where{\,|\,}                    % "where" separator in set's defs
\def\timeD#1{\dot{\overline{{#1}}}}

% ******************************************* USEFULL MACROS
\def\RomanEnum{\renewcommand{\labelenumi}{\rm (\roman{enumi})}}   % enumerate by roman numbers
\def\rf#1{(\ref{#1})}                                             % ref. shortcut
\def\prtl{\partial}                                        % partial deriv.
\def\Names#1{{\scshape #1}}
\def\rem#1{{\parskip=0cm\par!! {\sl\small #1} !!}}

\def\Xint#1{\mathchoice
{\XXint\displaystyle\textstyle{#1}}%
{\XXint\textstyle\scriptstyle{#1}}%
{\XXint\scriptstyle\scriptscriptstyle{#1}}%
{\XXint\scriptscriptstyle\scriptscriptstyle{#1}}%
\!\int}
\def\XXint#1#2#3{{\setbox0=\hbox{$#1{#2#3}{\int}$}
\vcenter{\hbox{$#2#3$}}\kern-.5\wd0}}
\def\ddashint{\Xint=}
\def\dashint{\Xint-}

% ******************************************* DOCUMENT NOTATIONS
% document specific
\def\rh{\varrho}
\def\vl{{\vc{u}}}
\def\th{\vartheta}
\def\vx{\vc{x}}
\def\vX{\vc{X}}
\def\vr{\vc{r}}
\def\veta{\vc{\eta}}
\def\dx{\,\d\vx}
\def\dt{\,\d t}
\def\bulk{\zeta}
\def\cS{\close{S}}
\def\eps{\varepsilon}
\def\phi{\varphi}
\def\Bog{{\mathcal B}}
\def\Riesz{{\mathcal R}}
\def\distr{\mathcal D}
\def\Item{$\bullet$}

\def\MEtst{\mathcal T}
%***************************************************************************
\setbeamercolor{my blue}{fg=blue}
\def\blue#1{{\usebeamercolor[fg]{my blue} #1}}

\setbeamercolor{my green}{fg=green}
\def\green#1{{\usebeamercolor[fg]{my green} #1}}

% color for term definition
\setbeamercolor{my orange}{fg=orange}
\def\df#1{{\usebeamercolor[fg]{my orange} #1}}
\def\xskip{{\vspace{2ex}}}

\def\cz#1{{\small (#1)}}

\def\E{\vc{\mathsf{E}}}

\begin{document}

\begin{frame}
  \titlepage
\end{frame}

\begin{frame}{Multinomial distribution \cz{multinomické rozdělení} }
Consider disjoint events $A_1,\dots A_k$, covering the probability space.\\
Their probabilities $P(A_i) = p_i$, $\sum_i p_i =1$.\\

\xskip
Probability that from $n$ trials there appear  $x_i$-times the event $A_i$ is
\[
 P(X_1 = x_1,\dots, X_k = x_k) = \frac{n!}{x_1!\dots x_k!}p_1^{x_1} \dots p_k^{x_k}
\]
for any set $\{x_i\in N \}$ with sum $n$.

\end{frame}

\begin{frame}{Goodness of fit \cz{Test dobré shody}}
\xskip
The quantity 
\[
 T=\sum_{i=1}^k \frac{ (X_i - np_i)^2}{np_i} = \frac{1}{n}\sum_{i=1}^k \frac{X_i^2}{p_i} - n
\]
has asymptoticaly $\chi^2_{k-1}$ distribution. 

\xskip
Good approximation for $np_i >5$ or rather\\
$k\ge 3$ and $np_i \ge 5q$, where $q$ is fraction of classes where $np_i<5$ (Yarnold 1970)

\xskip
This way, we can test if the quantity $X$ has discrete distribution with probabilities $p_i$.
\end{frame}

\begin{frame}{Example}
 Throwing 12 dies, we count number of sixths (r.v. $Y$).\\
 We distinguish following classes $Y=0,1,2,3,4,5,6$, $7$ and more.\\
 After $4096$ throws, we get frequencies in classes:
\[
 447, 1145, 1181, 796, 380, 115, 24, 8
\]
We test that r.v. $Y$ is from distribution  $Bi(12, 1/6)$\\

Under this assumption, we have theoretical frequencies:
\[
 np_i = n \binom{12}{i}\Big(\frac{1}{6}\Big)^i \Big(\frac{5}{6}\Big)^{12-i}
 \quad\text{for $i=0,\dots,6$}
\]
and $np_7 = n- \sum_{i=0}^6 np_i$. In particular:
\[
np_i = 459, 1103, 1213, 809, 364, 116, 27, 5
\]
$T = 5.484 $, $Q\chi^2_{7}(1-0.05) = 14.07$,\\
do not reject hypothesis about distribution of $Y$

\end{frame}


\begin{frame}[fragile]{Using R}
 \begin{verbatim}
> p=dbinom(0:6, size=12, p=1/6)                                                                                                                                                                                                                                                
> p[8] = 1-sum(p)
> p
[1] 0.112156655 0.269175971 0.296093569 0.197395712 0.088828071 0.028424983                                                                                                                                                                                                    
[7] 0.001292544                                                                                                                                                                                                                                                                
> x=c(447, 1145, 1181, 796, 380, 115, 24, 8)
> chisq.test(x, p=p)                                                                                                                                                                                                                                                
                                                                                                                                                                                                                                                                               
        Chi-squared test for given probabilities                                                                                                                                                                                                                               
                                                                                                                                                                                                                                                                               
data:  x                                                                                                                                                                                                                                                                       
X-squared = 5.4845, df = 7, p-value = 0.6011                                                                                                                                                                                                                                   
     
 \end{verbatim}
\end{frame}


\begin{frame}{Discretization of continuous data \cz{tříděná data}}
Necessary for: 
\begin{itemize}
 \item $\chi^2$-test, goodness of fit
 \item histogram
\end{itemize}

\xskip
data $x_1$, \dots, $x_n$
\begin{enumerate}
 \item identification of outliars, standardization (normal data)
 \item get data range $[a,b]=[min X, max X]$
 \item choose number $k$ or size $h$ of intervals:
    \begin{itemize}
     \item $k=\sqrt{n}$
     \item Sturges rule: $k=1+3.3 \log_{10} n$, pro malá $n$, normální data
     \item Scott's rule: $h = 3.5 S n^{-1/3}$
     \item Diaconis rule: $h = 2 IQR n^{-1/3}$
    \end{itemize}
 \item find $k$ disjoint intervals $(x_0, x_1)$, \dots $(x_{n-1}, x_n)$ covering $[a,b]$.
 \item (calculate theoretical frequancies in bins, possibly merge bins with small frequency)
\end{enumerate}
\end{frame}


\begin{frame}{\dots continued}
\begin{enumerate}
 \item data ze symetrického rozdělení: intervaly symetricky okolo průměru, nebo mediánu;
       jinak vhodné pokrytí intervalu $[a,b]$
 \item přesné četnosti v třídách:
       \[
          p_i = \int_{x_{i-1}}^{x_i}f(t) dt = F(x_{i}) - F(x_{i-1})
       \]
       $F$ je distr. fce pro teoretické rozdělení dat.
 \item odhady četností
      \[
        P_i = \frac{n_i}{n}
      \]
 \item odhad hustoty (histogram):
      \[
         f(x)= \frac{n_i}{n h_i}
      \]
\end{enumerate}
\end{frame}


\begin{frame}{Goodness of fit for normal data I} 
\begin{enumerate}
 \item standardization of data, z-coordinates: $Z_i = (X_i - \ol{X}) / S_X $
 \item choosing $k$ intervals $[x_{i-1}, x_i)$, frequencies $X_i$
 \item theoretical frequencies:\\
 $p_i = F(x_{i}) - F(x_{i-1})$ pro $N(0,1)$
 \item statistic:
\[
 T=\sum_{i=1}^k \frac{ (X_i - np_i)^2}{np_i} 
\]
\end{enumerate}
rejecting $H_0$ if $T \ge Q\chi^2_{k-3} (1-\alpha)$\\
 (we use  $k-3$ degrees of freedom, since we are estimating $2$ parameters)
\end{frame}

\begin{frame}{Goodness of fit for normal data II}
\begin{enumerate}
 \item Initial estimate $\mu = \ol{X}$ a $\sigma^2 = S_X^2$.
 \item Appropriate density and theoretical freq.:
\[
 f(x)=\frac{1}{\sqrt{2\pi}\sigma} \exp\Big\{-\frac{(x-\mu)^2}{2\sigma^2}\Big\},\quad p_i = \int_{x_{i-1}}^{x_i} f(x)
\]
  \item  improved estimate of parameters: 
\[
 \mu = \frac{1}{n}\sum_{i=1}^{k} \frac{X_i}{p_i} \int_{x_{i-1}}^{x_i} xf(x),
 \qquad
 \sigma^2 = \frac{1}{n}\sum_{i=1}^{k} \frac{X_i}{p_i} \int_{x_{i-1}}^{x_i} (x - \mu)^2 f(x),
\]
\item repeating 2), 3)
\item After stabilization of parameters, we compute the statistic:
\[
 T=\sum_{i=1}^k \frac{ (X_i - np_i)^2}{np_i} 
\]
\end{enumerate}
rejecting $H_0$ if $T \ge Q\chi^2_{k-3} (1-\alpha)$
\end{frame}


\end{document}
