
% $Header: /cvsroot/latex-beamer/latex-beamer/solutions/generic-talks/generic-ornate-15min-45min.en.tex,v 1.5 2007/01/28 20:48:23 tantau Exp $

\documentclass[smaller]{beamer}
\mode<presentation>
{
  \usetheme{Singapore}
  \usefonttheme[onlymath]{serif}
  % or ...
 %  \setbeamercovered{transparent}
  % or whatever (possibly just delete it)
}


\usepackage[czech]{babel}
% or whatever
\usepackage[utf8]{inputenc}
% or whatever
%\usepackage{times}
%\usepackage[T1]{fontenc}
% Or whatever. Note that the encoding and the font should match. If T1
% does not look nice, try deleting the line with the fontenc.


\title{PAS11 -- Analysis of variance (ANOVA)}

\author{Jan B\v rezina}
\institute % (optional, but mostly needed)
{
  %\inst{2}%
  Technical University of Liberec
}


% If you wish to uncover everything in a step-wise fashion, uncomment
% the following command: 

%\beamerdefaultoverlayspecification{<+->}

% ***************************************** SYMBOLS
\def\div{{\rm div}}
\def\Lapl{\Delta}
\def\grad{\nabla}
\def\supp{{\rm supp}}
\def\dist{{\rm dist}}
%\def\chset{\mathbbm{1}}
\def\chset{1}

\def\Tr{{\rm Tr}}
\def\sgn{{\rm sgn}}
\def\to{\rightarrow}
\def\weakto{\rightharpoonup}
\def\imbed{\hookrightarrow}
\def\cimbed{\subset\subset}
\def\range{{\mathcal R}}
\def\leprox{\lesssim}
\def\argdot{{\hspace{0.18em}\cdot\hspace{0.18em}}}
\def\Distr{{\mathcal D}}
\def\calK{{\mathcal K}}
\def\FromTo{|\rightarrow}
\def\convol{\star}
\def\impl{\Rightarrow}
\DeclareMathOperator*{\esslim}{esslim}
\DeclareMathOperator*{\esssup}{ess\,sup}
\DeclareMathOperator{\ess}{ess}
\DeclareMathOperator{\osc}{osc}
\DeclareMathOperator{\curl}{curl}

%\def\Ess{{\rm ess}}
%\def\Exp{{\rm exp}}
%\def\Implies{\Longrightarrow}
%\def\Equiv{\Longleftrightarrow}
% ****************************************** GENERAL MATH NOTATION
\def\Real{{\rm\bf R}}
\def\Rd{{{\rm\bf R}^{\rm 3}}}
\def\RN{{{\rm\bf R}^N}}
\def\D{{\mathbb D}}
\def\Nnum{{\mathbb N}}
\def\Measures{{\mathcal M}}
\def\d{\,{\rm d}}               % differential
\def\sdodt{\genfrac{}{}{}{1}{\rm d}{{\rm d}t}}
\def\dodt{\genfrac{}{}{}{}{\rm d}{{\rm d}t}}

\def\vc#1{\mathbf{\boldsymbol{#1}}}     % vector
\def\tn#1{{\mathbb{#1}}}    % tensor
\def\abs#1{\lvert#1\rvert}
\def\Abs#1{\bigl\lvert#1\bigr\rvert}
\def\bigabs#1{\bigl\lvert#1\bigr\rvert}
\def\Bigabs#1{\Big\lvert#1\Big\rvert}
\def\ABS#1{\left\lvert#1\right\rvert}
\def\norm#1{\bigl\Vert#1\bigr\Vert} %norm
\def\close#1{\overline{#1}}
\def\inter#1{#1^\circ}
\def\ol#1{\overline{#1}}
\def\ul#1{\underline{#1}}
\def\eqdef{\mathrel{\mathop:}=}     % defining equivalence
\def\where{\,|\,}                    % "where" separator in set's defs
\def\timeD#1{\dot{\overline{{#1}}}}

% ******************************************* USEFULL MACROS
\def\RomanEnum{\renewcommand{\labelenumi}{\rm (\roman{enumi})}}   % enumerate by roman numbers
\def\rf#1{(\ref{#1})}                                             % ref. shortcut
\def\prtl{\partial}                                        % partial deriv.
\def\Names#1{{\scshape #1}}
\def\rem#1{{\parskip=0cm\par!! {\sl\small #1} !!}}

\def\Xint#1{\mathchoice
{\XXint\displaystyle\textstyle{#1}}%
{\XXint\textstyle\scriptstyle{#1}}%
{\XXint\scriptstyle\scriptscriptstyle{#1}}%
{\XXint\scriptscriptstyle\scriptscriptstyle{#1}}%
\!\int}
\def\XXint#1#2#3{{\setbox0=\hbox{$#1{#2#3}{\int}$}
\vcenter{\hbox{$#2#3$}}\kern-.5\wd0}}
\def\ddashint{\Xint=}
\def\dashint{\Xint-}

% ******************************************* DOCUMENT NOTATIONS
% document specific
\def\rh{\varrho}
\def\vl{{\vc{u}}}
\def\th{\vartheta}
\def\vx{\vc{x}}
\def\vX{\vc{X}}
\def\vr{\vc{r}}
\def\veta{\vc{\eta}}
\def\dx{\,\d\vx}
\def\dt{\,\d t}
\def\bulk{\zeta}
\def\cS{\close{S}}
\def\eps{\varepsilon}
\def\phi{\varphi}
\def\Bog{{\mathcal B}}
\def\Riesz{{\mathcal R}}
\def\distr{\mathcal D}
\def\Item{$\bullet$}

\def\MEtst{\mathcal T}
%***************************************************************************
\setbeamercolor{my blue}{fg=blue}
\def\blue#1{{\usebeamercolor[fg]{my blue} #1}}

\setbeamercolor{my green}{fg=green}
\def\green#1{{\usebeamercolor[fg]{my green} #1}}

% color for term definition
\setbeamercolor{my orange}{fg=orange}
\def\df#1{{\usebeamercolor[fg]{my orange} #1}}
\def\xskip{{\vspace{2ex}}}

\def\cz#1{{\small (#1)}}

\def\E{\vc{\mathsf{E}}}

\begin{document}

\begin{frame}
  \titlepage
\end{frame}

\begin{frame}{Motivation problem}
(Amess et al. 1978) 22 bypass-surgery patients are randomly
divided into 3 treatment groups (different respiration). Is there difference in concentration of folic acid 
(vitamin B9) in red blood cells after 24 h?

\xskip
Group 1:
 243 
 251
 275
 291
 347
 354
 380
 392

Group 2:
 206
 210
 226
 249
 255
 273
 285
 295
 309

Group 3:
 241
 258
 270
 293
 328

\end{frame}


\begin{frame}{General problem}
  \begin{itemize}
   \item Comparison of mean values within several samples (groups)\\
   \item groups $i \in I$, ($I$, $I>2$).\\
   \item random vectors $Y_{i,j} = \mu_i+e$, $e~N(0,\sigma^2)$
   \item assuming same error $e$ !!
   \item $H_0: \mu_1=\mu_2=\dots\mu_I=\mu$      
   \item We are testing if the mean value depneds on the group/treatement.
 
  \end{itemize}

\end{frame}

\begin{frame}{Notation}
 $Y_{11}, \dots, Y_{1n_1}$ selection from $N(\mu_1, \sigma^2)$,\\
 \dots,\\
 $Y_{I1}, \dots, Y_{In_1}$ selection from $N(\mu_I, \sigma^2)$,\\
 Assuming same variance $\sigma^2$ for all groups.

\xskip
$I$ number of groups, $n_i$ size of groups (unbalanced ANOVA), total $n = n_1 + \dots + n_I$\\
group averages:
\[
 Y_{i.} = \sum_{j=1}^{n_i} Y_{ij},\quad \ol{Y}_i = \frac{Y_{i.}}{n_i}
\]
total average:
\[
 Y_{..} = \sum_{i_1}^{I}\sum_{j=1}^{n_i} Y_{ij},\quad \ol{Y} = \frac{Y_{..}}{n}
\]

\end{frame}

\begin{frame}{Sum of squares}
\begin{gather*}
  SS_{total}=\sum_i \sum_j (Y_{ij} - \ol{Y})^2 
  =\sum_i \sum_j (Y_{ij} - \ol{Y}_i + \ol{Y}_i - \ol{Y})^2 \\
  = 2\sum_i (\ol{Y}_i - \ol{Y}) \underbrace{\sum_j (Y_{ij} - \ol{Y}_i)}_{=0}
           +\underbrace{\sum_i (n_i-1)S_i^2}_{SS_{res}} + \underbrace{\sum_i n_i (\ol{Y}_i - \ol{Y})^2}_{SS_{group}}
\end{gather*}
\pause
\[
  SS_{group} = \sum_{i=1}^I n_i (\ol{Y}_i - \ol{Y})^2=\Big(\sum_{i=1}^I n_i \ol{Y}_i^2\Big) - n\ol{Y}^2
\]
\pause
\[
  SS_{res} = \sum_{i=1}^I (n_i - 1) S_i^2 = \sum_{i,j} Y_{ij}^2 - \sum_i n_i \ol{Y}_i^2
\]

\xskip
\dots enough to know $S_i$ and $\ol{Y}_i$, since $\ol{Y} = \frac{1}{n}\sum_i n_i \ol{Y}_i$
\end{frame}



\begin{frame}{ANOVA table}
Calculation of the statistics $F$ is summarized in the ANOVA table:

\xskip
\renewcommand*\arraystretch{1.5}
\begin{tabular}{c|c|c|c|c}
 & $SS$ & $df$ & $MS = SS/df$ & $F$ \\
\hline

groups & $SS_{g}$ & $df_g = I-1$ & $MS_g=SS_g / df_g$ & $F = MS_g/ s^2$\\
\hline
residual &$SS_{r}$ & $df_r = n-I$ & $MS_r=SS_r / df_r$ &  --- \\
\hline
total & $SS_t$ & $df_t = n-1$ & ---  & ---
\end{tabular}

\xskip
$s^2=MS_r$ is also called \df{residual variance}

\xskip
We in fact test hypothesis: $H_A: MS_g > MS_r$, thus
\[ p_{val} =1 - F_{df_g,df_r}(F) \]
\end{frame}

\begin{frame}[fragile]{Motivation example \dots preparing data}
\blue{from a text file}, anova.dat

\xskip
B9 concentration in dependance of respiration mixture
\begin{verbatim}
 conc   resp 
 243      1 
 ...
 241      3
 258      3 
\end{verbatim}
\begin{verbatim}
> B9=read.table("anova.dat", header=T)
> B9$resp = factor(B9$resp)     # make factor from numeric
\end{verbatim}
\end{frame}

\begin{frame}[fragile]{Motivation example \dots preparing data}
\blue{from individual vectors}
\begin{verbatim}
> treat1
[1] 243 251 275 291 347 354 380 392
> treat2
[1] 206 210 226 249 255 273 285 295 309
> treat3
[1] 241 258 270 293 328
> resp=factor(  c( rep(1,length(treat1)),
                   rep(2,length(treat2)),
                   rep(3,length(treat3)) ) )  
> conc=c(treat1,treat2,treat3)
> B9=data.frame(conc, resp) 
\end{verbatim}
\end{frame}

\begin{frame}[fragile]{Solving motivation example}
\begin{verbatim}
> attach(B9)

# per group mean, var, and group size
> Yi=tapply(conc, resp, mean)
> Vi=tapply(conc, resp, var)
> ni=tapply(conc, resp, length)

# total mean
> Y=mean(conc)
\end{verbatim}
\end{frame}

\begin{frame}[fragile]{Solving motivation example}
\begin{verbatim}
> SSg= sum( ni * (Yi-Y)^2)	;SSg
[1] 15515.77
> SSr=sum( (ni-1)*Vi )		;SSr
[1] 39716.1
> MSg=SSg/(3-1)			;MSg
[1] 7757.883
> MSr=SSr/(sum(ni)-3)		;MSr
[1] 2090.321
> MSg/MSr
[1] 3.711336
> pval=1-pf(MSg/MSr, 3-1, sum(ni)-3)
> pval
[1] 0.04358933 
\end{verbatim}
\end{frame}

\begin{frame}[fragile]{Using R anova}
\begin{verbatim}
> B9_aov=aov( conc ~ resp, B9)
> summary(B9_aov)
            Df Sum Sq Mean Sq F value Pr(>F)  
resp         2  15516    7758   3.711 0.0436 *
Residuals   19  39716    2090                 
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 

> coef(B9_aov)
(Intercept)       resp2       resp3 
  316.62500   -60.18056   -38.62500 
\end{verbatim}
\end{frame}

\begin{frame}{Post-hoc analysis}
Which pairs are responsible for rejecting H0?

\xskip
 Rejecting $H_0: \mu_i = \mu_j$ if
 \[
   U_{ij} = \frac{ \abs{\ol{Y}_i - \ol{Y}_j} }{ s \sqrt{\big(\frac{1}{n_i} + \frac{1}{n_j} \big)} } 
   \ge \frac{1}{\sqrt{2}} q_{I,n-I}(\alpha)
 \]
 $q_{m,n}(\alpha)$ tabulky --- Tukey's studentized range distribution.\\
 Nebo Scheffeova metoda (Fischerovo rozdělení):
 \[
    U_{ij} \ge \sqrt{(I-1)F_{I-1,n-I}(\alpha)}
 \]
 Nebo pouze Studentovo rozdělení:
 \[
     U_{ij} \ge t_{n-I}(\alpha)
 \] 
\end{frame}

\begin{frame}[fragile]{Using Tukey test in R}
\begin{verbatim}
> TukeyHSD(B9_aov)
  Tukey multiple comparisons of means
    95% family-wise confidence level

Fit: aov(formula = conc ~ resp, data = B9)

$resp
         diff        lwr      upr     p adj
2-1 -60.18056 -116.61904 -3.74207 0.0354792
3-1 -38.62500 -104.84037 27.59037 0.3214767
3-2  21.55556  -43.22951 86.34062 0.6802018
\end{verbatim}
 
\end{frame}



\begin{frame}{Kruskal-Wallis test}
samples (groups) $i\in I$:\\
\[
    \{Y_{ij}\}, j< n_i
\]
assume $Y_{ij} \sim X_i$ with same unknown variance $DX_i = \sigma$.

\xskip
$H_0: F_{X_i}^{-1}(0.5) = x_{0.5}$

\xskip
$H_A:$ different medians
\end{frame}

\begin{frame}[fragile]{K-W test procedure}
\begin{enumerate}
 \item sort all data $Y_{ij}$
 \item determine ranks $R_{ij}$, possibly average rank over same values\\
 \begin{tabular}{llllllll}
  values:& 33& 34& 34& 34& 35& 35& 37\\ 
  ranks: & 1 & 3 & 3 & 3 &4.5&4.5& 6
 \end{tabular}
 \item per group rank sums:
 \[
    T_i = \sum_{j=1}^{n_i} R_{ij}
 \]
 \item total rank sum:
 \[
    T = \sum_{i=1}^{I}\sum_{j=1}^{n_i} R_{ij} = N(N+1)/2
 \]
 \item statistics with approx. $\chi^2_{I-1}$ distribution:
 \[
   Q=\frac{12}{N(N+1)} \sum_{i=1}^{I} \frac{T_i^2}{n_i} - 3(N+1)
 \]
 \item 
 \[
   p_{val} = 1 - F_{I-1}(Q)
 \]
\end{enumerate}
\end{frame}

\begin{frame}[fragile]{K-W in R}
\begin{verbatim}
> kruskal.test(conc~resp, data=B9)

        Kruskal-Wallis rank sum test

data:  conc by resp
Kruskal-Wallis chi-squared = 4.1852, df = 2, p-value = 0.1234
\end{verbatim}
\end{frame}

\begin{frame}{KW posthoc analysis}
 
\end{frame}


\begin{frame}{Multifactor ANOVA}
 
\end{frame}

\begin{frame}{R-syntax}
% aov
% lm

% posthoc:
% pairwise.t.test
% TukeyHSD
\end{frame}


%Order of comparison (wikipedia)
%If there are a set of means (A, B, C, D), which can be ranked in the order A > B > C > D, not all possible comparisons need be tested using Tukey's test. 
%To avoid redundancy, one starts by comparing the largest mean (A) with the smallest mean (D). 
%If the qs value for the comparison of means A and D is less than the q value from the distribution,
%the null hypothesis is not rejected, and the means are said have no statistically significant difference between them.
%Since there is no difference between the two means that have the largest difference, comparing any two means that have 
%a smaller difference is assured to yield the same conclusion (if sample sizes are identical). As a result, no other comparisons need to be made.[2]

%Overall, it is important when employing Tukey's test to always start by comparing the largest mean to the smallest mean, 
%and then the largest mean with the next smallest, etc., until the largest mean has been compared to all other means 
%(or until no difference is found). After this, compare the second largest mean with the smallest mean, and then the next smallest, and so on. 
%Once again, if two means are found to have no statistically significant difference, do not compare any of the means between them.[2]

% Kruskal - Wallisův test (nenormalita)
% testování shody rozptylů
% stabilizace rozptylu
% dvojité třídění, interakce

\end{document}


